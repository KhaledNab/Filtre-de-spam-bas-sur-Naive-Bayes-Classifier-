{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fb212c5",
   "metadata": {},
   "source": [
    "# Filtre de spam bas√© sur \"Naive Bayes Classifier\" üìßüò°\n",
    "\n",
    "üòÅ N-K`\n",
    "<br><br>\n",
    "\n",
    "Sommaire :\n",
    " - <a href=\"#part1\">Pr√©sentation des donn√©es</a>\n",
    " - <a href=\"#part2\">Chargement des donn√©es</a> \n",
    " - <a href=\"#part3\">L'analyse exploratoire des donn√©es</a> \n",
    " - <a href=\"#part4\">Pr√©paration du classifieur Na√Øve Bayes</a>\n",
    " - <a href=\"#part5\">Entrainement du Naive Bayes Classifier</a> \n",
    " - <a href=\"#part5\">Tester et valider le Spam Filter</a>\n",
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ede579",
   "metadata": {},
   "source": [
    "## Pr√©sentation des donn√©es\n",
    "Ce notebook contient un jeux de donn√©es correspondants √† :\n",
    "- Colonne 1 : emails\n",
    "- Colonne 2 : spam ( 1 si \"oui\" 0 si \"non\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deba25cd",
   "metadata": {},
   "source": [
    "## Importation des libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7eb48e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk # Natural Language Toolkit (NLTK) est une plate-forme leader pour la cr√©ation de programmes Python pour travailler avec des donn√©es de langage humain\n",
    "from nltk.corpus import stopwords\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d018106f",
   "metadata": {},
   "source": [
    "## Chargement des donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "29dbba89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Subject: naturally irresistible your corporate...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Subject: the stock trading gunslinger  fanny i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Subject: unbelievable new homes made easy  im ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Subject: 4 color printing special  request add...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Subject: do not have money , get software cds ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  spam\n",
       "0  Subject: naturally irresistible your corporate...     1\n",
       "1  Subject: the stock trading gunslinger  fanny i...     1\n",
       "2  Subject: unbelievable new homes made easy  im ...     1\n",
       "3  Subject: 4 color printing special  request add...     1\n",
       "4  Subject: do not have money , get software cds ...     1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('emails.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb157665",
   "metadata": {},
   "source": [
    "## L'analyse exploratoire des donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ccc6145f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Describe :\n",
      "              spam\n",
      "count  5728.000000\n",
      "mean      0.238827\n",
      "std       0.426404\n",
      "min       0.000000\n",
      "25%       0.000000\n",
      "50%       0.000000\n",
      "75%       0.000000\n",
      "max       1.000000\n",
      "--------------------\n",
      "\n",
      " Infos :\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5728 entries, 0 to 5727\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    5728 non-null   object\n",
      " 1   spam    5728 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 89.6+ KB\n",
      "None\n",
      "--------------------\n",
      "\n",
      " Valeurs manquantes :\n",
      "text    0\n",
      "spam    0\n",
      "dtype: int64\n",
      "--------------------\n",
      "\n",
      " Redondance :\n",
      "(33, 2)\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"Describe :\")\n",
    "print(data.describe())\n",
    "print('-'*20)\n",
    "print(\"\\n Infos :\")\n",
    "print(data.info())\n",
    "print('-'*20)\n",
    "print(\"\\n Valeurs manquantes :\")\n",
    "print(data.isnull().sum())\n",
    "print('-'*20)\n",
    "print(\"\\n Redondance :\")\n",
    "print(data[data.duplicated() == True].shape)\n",
    "print('-'*20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be5f8a1",
   "metadata": {},
   "source": [
    "##### Donc nous n'avons pas de valeurs manquantes mais par contre nous avons des lignes r√©p√©t√©es (33 lignes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ecb800f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# suppression des lignes repet√©es\n",
    "data.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6349e3ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5695 entries, 0 to 5727\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    5695 non-null   object\n",
      " 1   spam    5695 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 133.5+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e6eb2f",
   "metadata": {},
   "source": [
    "## Pr√©paration du classifieur Na√Øve Bayes\n",
    "<br><br>\n",
    "Avant il faut faire les traitements necessaires sur le texte :\n",
    " - <a href=\"#part1\">Suppression des ponctuations</a>\n",
    " - <a href=\"#part2\">Suppression des stopwords</a> \n",
    " - <a href=\"#part3\">Retourner un texte pr√™t pour le traitement</a> \n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27eaeb66",
   "metadata": {},
   "source": [
    "### Suppression des ponctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bc879754",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "61ce89e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.Les ponctuations sont [!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~]\n",
    "#2.Les stopwords dans le traitement du langage naturel, sont des mots inutiles (donn√©es).\n",
    "\n",
    "def traitement_text(text):\n",
    "    \n",
    "     #1 Supprimer la ponctuationa\n",
    "        nopunc = [char for char in text if char not in string.punctuation]\n",
    "        nopunc = ''.join(nopunc)\n",
    "    \n",
    "     #2 Supprimer les mots vides\n",
    "        clean_words= [word for word in nopunc.split() if word.lower() not in stopwords.words('english')]\n",
    "    \n",
    "     #3 Renvoie une liste de mots clairs\n",
    "        return clean_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f46da891",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [Subject, naturally, irresistible, corporate, ...\n",
       "1    [Subject, stock, trading, gunslinger, fanny, m...\n",
       "2    [Subject, unbelievable, new, homes, made, easy...\n",
       "3    [Subject, 4, color, printing, special, request...\n",
       "4    [Subject, money, get, software, cds, software,...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Afficher la tokenisation (une liste de tokens)\n",
    "data['text'].head().apply(traitement_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbb867d",
   "metadata": {},
   "source": [
    "#### Il faut, pour chaque email, compter le nombre d'occurrences de mots. Cela permettra de calculer la probabilit√© conditionnelle.\n",
    "\n",
    "#### Il s'agit de la m√©thode fit_transform de la classe countVectorizer qui effectue ce calcul sur Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "56e6b8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d28b36dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "courriel = CountVectorizer(analyzer=traitement_text).fit_transform(data['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6125d5ed",
   "metadata": {},
   "source": [
    "## Entrainement du Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d26f36c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7162d1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Distribuer les donn√©es √† 80% pour entainer le mod√®le ML et 20% pour le test\n",
    "X_train, X_test, y_train, y_test = train_test_split(courriel, data['spam'], test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda7393a",
   "metadata": {},
   "source": [
    "#### Scikit_learn nous propose la classe MultinomialNB (NB pour Na√Øve Bayes) par la suite:\n",
    "- On donne √† MultinomialNB() la version codifi√©e des mails qu‚Äôon a calcul√© avec CountVectorizer\n",
    "- Pour chaque mail, on sp√©cifie s‚Äôil s‚Äôagit de SPAM ou non"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b3d1db2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c9339549",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = MultinomialNB().fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6d7267e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "#Afficher les valeurs pr√©dites\n",
    "print(classifier.predict(X_train))\n",
    "#Afficher les valeurs actuelles\n",
    "print(y_train.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a048379a",
   "metadata": {},
   "source": [
    "#### ALors on peut dire que les valeurs pr√©dites correspondent aux valeurs r√©elles. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a569d46",
   "metadata": {},
   "source": [
    "## Tester et valider le Spam Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cd3df0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "26f7841d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       870\n",
      "           1       0.97      1.00      0.98       269\n",
      "\n",
      "    accuracy                           0.99      1139\n",
      "   macro avg       0.98      0.99      0.99      1139\n",
      "weighted avg       0.99      0.99      0.99      1139\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val_pred = classifier.predict(X_test)\n",
    "print(classification_report(y_test,val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7fbaa106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrice de confusion : \n",
      " [[862   8]\n",
      " [  1 268]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Matrice de confusion : \\n\", confusion_matrix(y_test,val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "58405ca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pr√©cision du mod√®le : \n",
      " 0.9920983318700615\n"
     ]
    }
   ],
   "source": [
    "print(\"Pr√©cision du mod√®le : \\n\", accuracy_score(y_test,val_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2011dc84",
   "metadata": {},
   "source": [
    "### ALors on vient d‚Äôimpl√©menter un Spam Filter avec une precision de 99.2%  ü•≥üéâüéä"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
